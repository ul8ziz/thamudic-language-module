import streamlit as st
import torch
import numpy as np
import cv2
from PIL import Image
import io
import sys
import os
import logging
from torchvision import transforms

class ThamudicApp:
    def __init__(self):
        """
        Initialize the Thamudic Translation Application
        """
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        try:
            # Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø®Ø±ÙŠØ·Ø©
            self.model_path = os.path.join(self.project_root, 'models/best_model.pth')
            self.mapping_file = os.path.join(self.project_root, 'data/char_mapping.json')
            
            # ØªØ­Ù…ÙŠÙ„ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø­Ø±Ù
            from utils import load_char_mapping
            self.char_mapping = load_char_mapping(self.mapping_file)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØ±Ø¬Ù…
            from model import ThamudicTranslator
            self.translator = ThamudicTranslator(
                model_path=self.model_path, 
                char_mapping=self.char_mapping
            )
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")
            raise
    
    def preprocess_image(self, uploaded_file):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
        
        Args:
            uploaded_file: Ù…Ù„Ù Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹ Ù…Ù† Streamlit
        
        Returns:
            torch.Tensor: Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØªØ§Ù†Ø³ÙˆØ±
        """
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
        image = Image.open(uploaded_file).convert('L')
        img_array = np.array(image)
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        img_array = clahe.apply(img_array)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø±Ø´Ø­ Ø«Ù†Ø§Ø¦ÙŠ
        img_array = cv2.bilateralFilter(img_array, 9, 75, 75)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø© ØªÙƒÙŠÙÙŠØ©
        binary = cv2.adaptiveThreshold(
            img_array, 
            255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV,
            11,
            2
        )
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
        kernel = np.ones((2,2), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        # ØªØ­ÙˆÙŠÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© PIL
        image = Image.fromarray(binary)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†ÙØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ])
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªØ§Ù†Ø³ÙˆØ±
        image_tensor = transform(image)
        image_tensor = image_tensor.unsqueeze(0)
        
        return image_tensor
    
    def show_system_info(self):
        """
        Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ù…Ù„ÙØ§Øª
        """
        with st.expander("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ğŸ”"):
            st.markdown("### Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù†Ø¸Ø§Ù…")
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
            st.write("#### Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª:")
            st.code(f"""
            - Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {os.path.abspath(self.model_path)}
            - Ù…Ù„Ù Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø­Ø±Ù: {os.path.abspath(self.mapping_file)}
            """)
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
            st.write("#### Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª:")
            st.code(f"""
            - Python: {sys.version.split()[0]}
            - Torch: {torch.__version__}
            - OpenCV: {cv2.__version__}
            - NumPy: {np.__version__}
            - Pillow: {Image.__version__}
            """)
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø­Ø±Ù
            st.write("#### Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø­Ø±Ù:")
            st.write(f"- Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: {len(self.char_mapping)}")
            
            if st.checkbox("Ø¹Ø±Ø¶ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„ÙƒØ§Ù…Ù„Ø©"):
                st.json(self.char_mapping)

    def show_project_files(self):
        """
        Ø¹Ø±Ø¶ Ù…Ø­ØªÙˆÙŠØ§Øª Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
        """
        st.markdown("### ğŸ“‚ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ Ø¹Ø±Ø¶Ù‡Ø§
        important_extensions = {'.py', '.json', '.txt', '.md', '.yml', '.yaml'}
        
        def is_important_file(filename):
            return any(filename.endswith(ext) for ext in important_extensions)
        
        def read_file_content(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    return f.read()
            except Exception as e:
                return f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}"
        
        # Ù…Ø³Ø­ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª
        for root, dirs, files in os.walk(self.project_root):
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø®Ø§ØµØ©
            dirs[:] = [d for d in dirs if not d.startswith(('.', '__', 'venv', 'env'))]
            
            rel_path = os.path.relpath(root, self.project_root)
            if rel_path == '.':
                st.markdown("#### ğŸ“ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ")
            else:
                st.markdown(f"#### ğŸ“ {rel_path}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ù„Ø¯
            for file in files:
                if is_important_file(file):
                    filepath = os.path.join(root, file)
                    st.markdown(f"**ğŸ“„ {file}**")
                    content = read_file_content(filepath)
                    st.code(content, language='python')

    def run(self):
        """
        ØªØ´ØºÙŠÙ„ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©
        """
        # Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
        st.title('ğŸ”¤ Ù…ØªØ±Ø¬Ù… Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©')
        

        # ÙˆØµÙ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
        st.markdown('''
        ### ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        - Ù‚Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ø±ÙˆÙ Ø«Ù…ÙˆØ¯ÙŠØ©
        - Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ ÙˆØ¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡Ø§
        ''')
        
        # Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©", 
            type=['png', 'jpg', 'jpeg']
        )
        
        if uploaded_file is not None:
            try:
                # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                col1, col2 = st.columns(2)
                with col1:
                    st.image(uploaded_file, caption='Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©', use_container_width=True)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
                processed_image = self.preprocess_image(uploaded_file)
                logging.info("ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­")
                
                # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                with col2:
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¹Ø±Ø¶
                    processed_display = processed_image.squeeze()
                    logging.info(f"Ø´ÙƒÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processed_display.shape}")
                    
                    if processed_display.dim() == 2:  # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ø¹Ø¯ÙŠÙ† ÙÙ‚Ø·
                        processed_display = processed_display.unsqueeze(0)  # Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ù‚Ù†Ø§Ø©
                        logging.info("ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ù‚Ù†Ø§Ø© Ù„Ù„ØµÙˆØ±Ø©")
                    
                    processed_display = processed_display.permute(1, 2, 0)  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
                    logging.info(f"Ø´ÙƒÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨: {processed_display.shape}")
                    
                    # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠØ¹
                    processed_display = processed_display * torch.tensor([0.5]) + torch.tensor([0.5])
                    logging.info(f"Ù…Ø¯Ù‰ Ù‚ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø©: [{processed_display.min():.2f}, {processed_display.max():.2f}]")
                    
                    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ NumPy
                    processed_display = processed_display.numpy()
                    # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ… Ø¨ÙŠÙ† 0 Ùˆ 1
                    processed_display = np.clip(processed_display, 0, 1)
                    st.image(processed_display, caption='Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©', use_container_width=True)
                
                # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ
                logging.info("Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ...")
                predictions = self.translator.predict(processed_image)
                logging.info(f"Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª: {len(predictions)}")
                
                # Ø¹Ø±Ø¶ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ¹Ø±Ù
                st.markdown('## Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ¹Ø±Ù')
                
                # Ø¬Ø¯ÙˆÙ„ Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ø¹ØªØ±Ù Ø¨Ù‡Ø§
                results_data = []
                for char, confidence in predictions:
                    logging.info(f"Ø§Ù„Ø­Ø±Ù: {char}, Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©: {confidence:.4f}")
                    results_data.append({
                        'Ø§Ù„Ø­Ø±Ù': char,
                        'Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©': f'{confidence * 100:.2f}%'
                    })
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                if results_data:
                    st.table(results_data)
                    
                    # Ø±Ø³Ù… Ù…Ø±Ø¨Ø¹ Ø£Ø®Ø¶Ø± Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ø¹ØªØ±Ù Ø¨Ù‡Ø§
                    st.markdown('''
                    <style>
                    .green-box {
                        border: 3px solid green;
                        border-radius: 10px;
                        padding: 10px;
                        text-align: center;
                        background-color: rgba(0, 255, 0, 0.1);
                        display: flex;
                        justify-content: center;
                        align-items: center;
                    }
                    </style>
                    ''', unsafe_allow_html=True)
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø±ÙˆÙ ÙÙŠ Ù…Ø±Ø¨Ø¹ Ø£Ø®Ø¶Ø±
                    chars_text = ' '.join([char for char, _ in predictions if confidence > 0.3])
                    st.markdown(f'''
                    <div class="green-box">
                        <h2 style="color: green;">{chars_text}</h2>
                    </div>
                    ''', unsafe_allow_html=True)
                else:
                    st.warning('âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø±ÙˆÙ Ø¨Ø´ÙƒÙ„ Ù…Ø¤ÙƒØ¯')
                
            except Exception as e:
                st.error(f'Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}')

def main():
    """
    Ø¯Ø§Ù„Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    """
    logging.basicConfig(level=logging.INFO)
    app = ThamudicApp()
    app.run()

if __name__ == "__main__":
    main()