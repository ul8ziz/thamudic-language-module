import streamlit as st
import os
import json
import torch
import numpy as np
from PIL import Image, ImageDraw
import albumentations as A
from thamudic_model import ThamudicRecognitionModel
import logging
import cv2

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def load_model():
    """
    ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©
    """
    try:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_path = os.path.join(base_dir, 'models', 'best_model.pth')
        mapping_file = os.path.join(base_dir, 'data', 'mapping.json')
        letters_file = os.path.join(base_dir, 'data', 'thamudic_to_arabic.json')
        
        if not os.path.exists(model_path):
            st.error("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹.")
            return None, None, None
            
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¹ÙŠÙŠÙ†
        with open(mapping_file, 'r', encoding='utf-8') as f:
            class_mapping = json.load(f)
            
        # ØªØ­Ù…ÙŠÙ„ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        with open(letters_file, 'r', encoding='utf-8') as f:
            letters_mapping = json.load(f)
            
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = ThamudicRecognitionModel(num_classes=len(class_mapping))
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
        model.eval()
        
        return model, class_mapping, letters_mapping
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
        return None, None, None

def preprocess_image(image):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„ØªÙ†Ø¨Ø¤
    """
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image_np = np.array(image)
    
    # ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
    transform = A.Compose([
        A.Resize(224, 224),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
    transformed = transform(image=image_np)
    image_tensor = torch.from_numpy(transformed['image']).permute(2, 0, 1).float()
    
    # Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ø¯ÙØ¹Ø©
    image_tensor = image_tensor.unsqueeze(0)
    
    return image_tensor

def detect_letters(image):
    """
    Ø§ÙƒØªØ´Ø§Ù Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø­Ø±ÙˆÙ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
    """
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
    gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø© Ø«Ù†Ø§Ø¦ÙŠØ© ØªÙƒÙŠÙÙŠØ©
    binary = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªØµÙ„Ø©
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)
    
    # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ù„ÙÙŠØ© (Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø£ÙˆÙ„)
    boxes = []
    for i in range(1, num_labels):
        x = stats[i, cv2.CC_STAT_LEFT]
        y = stats[i, cv2.CC_STAT_TOP]
        w = stats[i, cv2.CC_STAT_WIDTH]
        h = stats[i, cv2.CC_STAT_HEIGHT]
        area = stats[i, cv2.CC_STAT_AREA]
        
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
        if area > 100 and area < (image.size[0] * image.size[1]) / 4:
            boxes.append((x, y, w, h))
    
    return boxes

def draw_boxes(image, boxes, predictions, letters_mapping):
    """
    Ø±Ø³Ù… Ù…Ø±Ø¨Ø¹Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…Ø¹ ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
    """
    draw = ImageDraw.Draw(image)
    
    for i, ((x, y, w, h), (thamudic_letter, confidence)) in enumerate(zip(boxes, predictions)):
        # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹
        draw.rectangle(
            [(x, y), (x + w, y + h)],
            outline='lime',
            width=2
        )
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„
        arabic_letter = letters_mapping.get(thamudic_letter, "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
        text = f"letter_{i+1}: {arabic_letter} - {thamudic_letter}"
        draw.text((x, y-20), text, fill='lime')
    
    return image

def main():
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
    st.set_page_config(
        page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚ÙˆØ´ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    # Ø¥Ø¶Ø§ÙØ© CSS Ù…Ø®ØµØµ
    st.markdown("""
        <style>
        .stApp {
            direction: rtl;
            text-align: right;
        }
        .css-1d391kg {
            padding: 1rem;
            background-color: #f0f2f6;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
        }
        .stButton>button {
            width: 100%;
            margin-top: 1rem;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    st.title("Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚ÙˆØ´ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©")
    st.markdown("---")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model, class_mapping, letters_mapping = load_model()
    
    if model is None or class_mapping is None or letters_mapping is None:
        return
        
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    st.subheader("ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø©")
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù„Ù†Ù‚Ø´ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠ", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file is not None:
        try:
            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            original_image = Image.open(uploaded_file).convert('RGB')
            
            # Ø§ÙƒØªØ´Ø§Ù Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø­Ø±ÙˆÙ
            boxes = detect_letters(original_image)
            
            predictions = []
            for x, y, w, h in boxes:
                # Ø§Ù‚ØªØµØ§Øµ Ø§Ù„Ø­Ø±Ù
                letter_image = original_image.crop((x, y, x+w, y+h))
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
                image_tensor = preprocess_image(letter_image)
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                with torch.no_grad():
                    outputs = model(image_tensor)
                    probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
                    predicted_idx = torch.argmax(probabilities).item()
                    confidence = probabilities[predicted_idx].item() * 100
                    
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ø­Ø±Ù
                predicted_letter = None
                for letter, idx in class_mapping.items():
                    if idx == predicted_idx:
                        predicted_letter = letter
                        break
                
                # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…Ø© Ø§Ø³ØªÙÙ‡Ø§Ù…
                if predicted_letter is None:
                    predicted_letter = "?"
                
                predictions.append((predicted_letter, confidence))
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± ÙÙŠ ØµÙÙŠÙ†
            st.subheader("Ø§Ù„ØµÙˆØ±")
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©**")
                st.image(original_image, use_container_width=True)
            
            with col2:
                st.markdown("**Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ¹Ø±Ù**")
                # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª ÙˆØ§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                result_image = original_image.copy()
                result_image = draw_boxes(result_image, boxes, predictions, letters_mapping)
                st.image(result_image, use_container_width=True)
            
            # Ø¥Ø¶Ø§ÙØ© Ø®Ø· ÙØ§ØµÙ„
            st.markdown("---")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„
            st.subheader("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ø±Ù")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„
            table_data = []
            for i, ((x, y, w, h), (thamudic_letter, confidence)) in enumerate(zip(boxes, predictions)):
                arabic_letter = letters_mapping.get(thamudic_letter, "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
                table_data.append({
                    "Ø±Ù‚Ù… Ø§Ù„Ø­Ø±Ù": f"letter_{i+1}",
                    "Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠ": arabic_letter,
                    "Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠ": thamudic_letter,
                    "Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©": f"{confidence:.1f}%"
                })
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            if table_data:
                st.table(table_data)
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø±ÙˆÙ Ø¨Ø´ÙƒÙ„ Ù…Ø¤ÙƒØ¯")
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
            
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    with st.expander("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"):
        st.write("""
        - Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© Ø¹Ù…ÙŠÙ‚Ø© Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©.
        - Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† ØµÙˆØ± Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©.
        - Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© ÙˆÙˆØ¶ÙˆØ­Ù‡Ø§.
        - ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø­Ø±ÙˆÙ ÙÙŠ Ù†ÙØ³ Ø§Ù„ØµÙˆØ±Ø©.
        """)

if __name__ == "__main__":
    main()
