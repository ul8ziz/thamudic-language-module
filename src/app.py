import streamlit as st
import os
import json
import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import albumentations as A
from thamudic_model import ThamudicRecognitionModel
import logging
import cv2
from PIL import ImageFont

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def load_model():
    """
    ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©
    """
    try:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_path = os.path.join(base_dir, 'models', 'best_model.pth')
        mapping_file = os.path.join(base_dir, 'data', 'mapping.json')
        letters_file = os.path.join(base_dir, 'data', 'thamudic_to_arabic.json')
        
        if not os.path.exists(model_path):
            st.error("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹.")
            return None, None, None
            
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¹ÙŠÙŠÙ†
        with open(mapping_file, 'r', encoding='utf-8') as f:
            class_mapping = json.load(f)
            
        # ØªØ­Ù…ÙŠÙ„ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        with open(letters_file, 'r', encoding='utf-8') as f:
            letters_mapping = json.load(f)
            
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = ThamudicRecognitionModel(num_classes=len(class_mapping))
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
        model.eval()
        
        return model, class_mapping, letters_mapping
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
        return None, None, None

def preprocess_image(image):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„ØªÙ†Ø¨Ø¤
    """
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image_np = np.array(image)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
    if len(image_np.shape) == 3:
        image_gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    else:
        image_gray = image_np
        
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    image_enhanced = clahe.apply(image_gray)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø© ØªÙƒÙŠÙÙŠØ©
    binary = cv2.adaptiveThreshold(
        image_enhanced, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© Ø¥Ù„Ù‰ RGB
    image_rgb = cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB)
    
    # ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
    transform = A.Compose([
        A.Resize(224, 224),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
    transformed = transform(image=image_rgb)
    image_tensor = torch.from_numpy(transformed['image']).permute(2, 0, 1).float()
    
    # Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ø¯ÙØ¹Ø©
    image_tensor = image_tensor.unsqueeze(0)
    
    return image_tensor

def detect_letters(image):
    """
    Ø§ÙƒØªØ´Ø§Ù Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø­Ø±ÙˆÙ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
    """
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
    image_np = np.array(image)
    if len(image_np.shape) == 3:
        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    else:
        gray = image_np
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø© ØªÙƒÙŠÙÙŠØ©
    binary = cv2.adaptiveThreshold(
        enhanced, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
    kernel = np.ones((3,3), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªØµÙ„Ø©
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)
    
    # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ù„ÙÙŠØ© (Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø£ÙˆÙ„)
    boxes = []
    for i in range(1, num_labels):
        x = stats[i, cv2.CC_STAT_LEFT]
        y = stats[i, cv2.CC_STAT_TOP]
        w = stats[i, cv2.CC_STAT_WIDTH]
        h = stats[i, cv2.CC_STAT_HEIGHT]
        area = stats[i, cv2.CC_STAT_AREA]
        
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
        min_area = 100
        max_area = (image.size[0] * image.size[1]) / 8
        if min_area < area < max_area:
            # Ø¥Ø¶Ø§ÙØ© Ù‡Ø§Ù…Ø´ Ø­ÙˆÙ„ Ø§Ù„Ø­Ø±Ù
            margin = 5
            x = max(0, x - margin)
            y = max(0, y - margin)
            w = min(image.size[0] - x, w + 2 * margin)
            h = min(image.size[1] - y, h + 2 * margin)
            boxes.append((x, y, w, h))
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±
    boxes.sort(key=lambda box: box[0], reverse=True)
    
    return boxes

def map_letter_to_thamudic(letter_name, class_mapping):
    """
    Map generic letter names to their corresponding Thamudic character index
    """
    # Reverse the class_mapping to get index to letter_name mapping
    index_to_letter = {v: k for k, v in class_mapping.items()}
    
    # Extract the number from the letter name
    try:
        index = int(letter_name.split('_')[1]) - 1
        return index_to_letter.get(index, letter_name)
    except (IndexError, ValueError):
        return letter_name

def draw_boxes(image, boxes, predictions, letters_mapping, class_mapping):
    """
    Draw bounding boxes around detected letters with predictions
    
    Args:
        image: Input image
        boxes: List of bounding boxes
        predictions: List of predicted classes
        letters_mapping: Mapping from Thamudic to Arabic letters
        class_mapping: Mapping from class names to indices
    """
    try:
        # Create a copy of the image
        result_image = image.copy()
        draw = ImageDraw.Draw(result_image)
        
        # Create reverse mappings
        reverse_class_mapping = {v: k for k, v in class_mapping.items()}
        
        # Font settings
        font_size = 20
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()
        
        # Draw boxes and predictions
        for box, pred in zip(boxes, predictions):
            x1, y1, x2, y2 = box
            
            # Draw rectangle with green color
            draw.rectangle([x1, y1, x2, y2], outline='lime', width=2)
            
            # Get letter names
            thamudic_letter = reverse_class_mapping[pred]
            arabic_letter = letters_mapping.get(thamudic_letter, "?")
            
            # Calculate text position
            text_width = max(x2 - x1, font_size * 3)
            text_x = x1
            text_y = y1 - font_size - 5
            
            # Draw background rectangle for text
            draw.rectangle([text_x, text_y, text_x + text_width, text_y + font_size],
                         fill='white', outline='lime')
            
            # Draw text
            text = f"{arabic_letter} | {thamudic_letter}"
            draw.text((text_x + 2, text_y), text, fill='black', font=font)
        
        return result_image
        
    except Exception as e:
        logging.error(f"Error in draw_boxes: {str(e)}")
        return image

def main():
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
    st.set_page_config(
        page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚ÙˆØ´ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    # Ø¥Ø¶Ø§ÙØ© CSS Ù…Ø®ØµØµ
    st.markdown("""
        <style>
        .stApp {
            direction: rtl;
            text-align: right;
        }
        .css-1d391kg {
            padding: 1rem;
            background-color: #f0f2f6;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
        }
        .stButton>button {
            width: 50%;
            margin-top: 1rem;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    st.title("Ù…ÙˆØ¯Ù„ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚ÙˆØ´ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©")
    st.markdown("---")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model, class_mapping, letters_mapping = load_model()
    
    if model is None or class_mapping is None or letters_mapping is None:
        return
        
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    st.subheader("ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø©")
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù„Ù†Ù‚Ø´ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠ", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file is not None:
        try:
            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            original_image = Image.open(uploaded_file).convert('RGB')
            
            # Ø§ÙƒØªØ´Ø§Ù Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø­Ø±ÙˆÙ
            boxes = detect_letters(original_image)
            
            predictions = []
            converted_boxes = []  # Ù‚Ø§Ø¦Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø§Ù„Ù…Ø­ÙˆÙ„Ø©
            for x, y, w, h in boxes:
                # ØªØ­ÙˆÙŠÙ„ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚
                converted_boxes.append((x, y, x+w, y+h))
                
                # Ø§Ù‚ØªØµØ§Øµ Ø§Ù„Ø­Ø±Ù
                letter_image = original_image.crop((x, y, x+w, y+h))
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
                image_tensor = preprocess_image(letter_image)
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                with torch.no_grad():
                    outputs = model(image_tensor)
                    probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
                    predicted_idx = torch.argmax(probabilities).item()
                    confidence = probabilities[predicted_idx].item() * 100
                    
                predictions.append(predicted_idx)  # ØªØ®Ø²ÙŠÙ† ÙÙ‚Ø· Ù…Ø¤Ø´Ø± Ø§Ù„ØªÙ†Ø¨Ø¤
            
            if predictions:
                st.markdown("**Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ¹Ø±Ù**")
                # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª ÙˆØ§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                result_image = original_image.copy()
                result_image = draw_boxes(result_image, converted_boxes, predictions, letters_mapping, class_mapping)
                st.image(result_image, use_container_width=True)
            
            # Ø¥Ø¶Ø§ÙØ© Ø®Ø· ÙØ§ØµÙ„
            st.markdown("---")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„
            st.subheader("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ø±Ù")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„
            table_data = []
            for i, ((x, y, w, h), pred) in enumerate(zip(boxes, predictions)):
                thamudic_letter = None
                for letter, idx in class_mapping.items():
                    if idx == pred:
                        thamudic_letter = letter
                        break
                arabic_letter = letters_mapping.get(thamudic_letter, "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
                table_data.append({
                    "Ø±Ù‚Ù… Ø§Ù„Ø­Ø±Ù": f"letter_{i+1}",
                    "Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠ": arabic_letter,
                    "Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠ": thamudic_letter,
                    "Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©": f"{confidence:.1f}%"
                })
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            if table_data:
                st.table(table_data)
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø±ÙˆÙ Ø¨Ø´ÙƒÙ„ Ù…Ø¤ÙƒØ¯")
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
            
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    with st.expander("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"):
        st.write("""
        - Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© Ø¹Ù…ÙŠÙ‚Ø© Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©.
        - Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† ØµÙˆØ± Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©.
        - Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© ÙˆÙˆØ¶ÙˆØ­Ù‡Ø§.
        - ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø­Ø±ÙˆÙ ÙÙŠ Ù†ÙØ³ Ø§Ù„ØµÙˆØ±Ø©.
        """)

if __name__ == "__main__":
    main()
