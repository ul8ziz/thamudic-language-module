import os
import json
import logging
import numpy as np
import streamlit as st
from PIL import Image
import tensorflow as tf

def load_model_and_mapping():
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ®Ø±ÙŠØ·Ø© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
    """
    try:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_path = os.path.join(base_dir, 'models', 'best_model.h5')
        model_arch_path = os.path.join(base_dir, 'models', 'best_model_architecture.json')
        model_weights_path = os.path.join(base_dir, 'models', 'best_model_weights.h5')
        mapping_path = os.path.join(base_dir, 'data', 'letters', 'letter_mapping.json')
        
        if not os.path.exists(mapping_path):
            st.error("Ù…Ù„Ù Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø­Ø±ÙˆÙ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
            return None, None
            
        # Try loading full model first
        if os.path.exists(model_path):
            try:
                model = tf.keras.models.load_model(model_path)
                st.success("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
            except Exception as e:
                logging.error(f"Error loading full model: {str(e)}")
                model = None
        else:
            model = None
            
        # If full model loading failed, try loading from architecture and weights
        if model is None and os.path.exists(model_arch_path) and os.path.exists(model_weights_path):
            try:
                # Load architecture
                with open(model_arch_path, 'r') as f:
                    model_json = f.read()
                model = tf.keras.models.model_from_json(model_json)
                
                # Load weights
                model.load_weights(model_weights_path)
                
                # Compile model
                model.compile(
                    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
                    loss='categorical_crossentropy',
                    metrics=['accuracy']
                )
                
                st.success("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù† Ø¨Ù†Ø¬Ø§Ø­!")
            except Exception as e:
                st.error(f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù†: {str(e)}")
                return None, None
        elif model is None:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹.")
            return None, None
            
        # Load label mapping
        with open(mapping_path, 'r', encoding='utf-8') as f:
            mapping_data = json.load(f)
            thamudic_letters = mapping_data['thamudic_letters']
            
        return model, thamudic_letters
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
        logging.error(f"Error loading model: {str(e)}")
        return None, None

def preprocess_image(image):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„ØªØ¹Ø±Ù
    """
    try:
        # Convert to RGB if needed
        if image.mode != 'RGB':
            image = image.convert('RGB')
            
        # Resize
        image = image.resize((128, 128))
        
        # Convert to array and normalize
        img_array = np.array(image) / 255.0
        
        # Add batch dimension
        img_array = np.expand_dims(img_array, axis=0)
        
        return img_array
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
        return None

def main():
    st.set_page_config(
        page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø«Ù…ÙˆØ¯ÙŠØ©")
    st.markdown("""
    <style>
        .stTitle {
            text-align: center;
            direction: rtl;
        }
        .stMarkdown {
            direction: rtl;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Load model and mapping
    model, thamudic_letters = load_model_and_mapping()
    
    if model is None or thamudic_letters is None:
        return
        
    # File uploader
    st.markdown("<h3 style='text-align: right;'>ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„ÙŠÙ‡Ø§</h3>", unsafe_allow_html=True)
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©...", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file is not None:
        try:
            # Display uploaded image
            image = Image.open(uploaded_file)
            st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ù…Ù„Ø©", use_column_width=True)
            
            # Preprocess image
            processed_image = preprocess_image(image)
            if processed_image is None:
                return
                
            # Make prediction
            predictions = model.predict(processed_image)[0]
            
            # Get top 3 predictions
            top_indices = np.argsort(predictions)[-3:][::-1]
            
            # Display results
            st.markdown("<h3 style='text-align: right;'>Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ø±Ù:</h3>", unsafe_allow_html=True)
            
            for idx in top_indices:
                confidence = predictions[idx] * 100
                letter = next((letter for letter in thamudic_letters if letter['index'] == idx), None)
                if letter:
                    st.markdown(
                        f"<div style='text-align: right; direction: rtl;'>"
                        f"<h4>{letter['name']} ({letter['symbol']})</h4>"
                        f"<p>Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©: {confidence:.2f}%</p>"
                        f"<p>{letter['description']}</p>"
                        f"</div>",
                        unsafe_allow_html=True
                    )
                    
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
            logging.error(f"Error processing image: {str(e)}")

if __name__ == "__main__":
    main()
